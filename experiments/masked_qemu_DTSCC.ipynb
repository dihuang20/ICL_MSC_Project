{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# This source code file refers to:\n",
    "# https://github.com/ICL-ml4csec/VulBERTa\n",
    "# https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "# https://huggingface.co/docs/transformers/model_doc/roberta\n",
    "# https://colab.research.google.com/github/dpressel/dlss-tutorial/blob/master/1_pretrained_vectors.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def write_to_file(text, path, mode='a'): # 'a': append; 'w': overwrite\n",
    "    with open(path, mode) as f:\n",
    "        f.write(text)\n",
    "\n",
    "def mkdir_if_not_exist(directory):\n",
    "    if not directory: return\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "def remove_file_if_exist(path):\n",
    "    if not path: return\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            shutil.rmtree(path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using', device)\n",
    "\n",
    "# The following randomization refers to: https://github.com/ICL-ml4csec/VulBERTa/blob/main/Finetuning_VulBERTa-MLP.ipynb\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "# -------------------------------------- start\n",
    "\n",
    "DATASET_NAME = 'qemu'\n",
    "DATASET_MASKING = 'masked_'\n",
    "# DATASET_MASKING = ''\n",
    "\n",
    "codeTF_check_point = 'checkpoint-6681'\n",
    "msgTF_check_point = 'roberta_large_cnn_0.794_ep15(masked_qemu_msgTF).pt'\n",
    "\n",
    "# -------------------------------------- end\n",
    "\n",
    "root_directory = '/root/autodl-tmp'\n",
    "dataset_directory = f'{root_directory}/output_dataset_1/{DATASET_MASKING}{DATASET_NAME}'\n",
    "init_train_path = f'{dataset_directory}/train.json'\n",
    "init_val_path = f'{dataset_directory}/val.json'\n",
    "init_test_path = f'{dataset_directory}/test.json'\n",
    "intermediate_directory = f'{root_directory}/intermediate/{DATASET_MASKING}{DATASET_NAME}'\n",
    "mkdir_if_not_exist(f'{root_directory}/intermediate')\n",
    "mkdir_if_not_exist(intermediate_directory)\n",
    "\n",
    "finetuned_ct_model_path = f'{root_directory}/codeTF_check_point/{DATASET_MASKING}{DATASET_NAME}/{codeTF_check_point}'\n",
    "intermediate_ct_train_path = f'{intermediate_directory}/ct_train.txt'\n",
    "intermediate_ct_val_path = f'{intermediate_directory}/ct_val.txt'\n",
    "intermediate_ct_test_path = f'{intermediate_directory}/ct_test.txt'\n",
    "\n",
    "finetuned_mt_model_path = f'{root_directory}/msgTF_check_point/{DATASET_MASKING}{DATASET_NAME}/{msgTF_check_point}'\n",
    "intermediate_mt_train_path = f'{intermediate_directory}/mt_train.txt'\n",
    "intermediate_mt_val_path = f'{intermediate_directory}/mt_val.txt'\n",
    "intermediate_mt_test_path = f'{intermediate_directory}/mt_test.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CodeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating codeTF intermediate dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:05<00:00,  1.80s/it]\n",
      "100%|██████████| 24/24 [00:42<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:42<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[1267  471]\n",
      " [ 564  667]]\n",
      "\n",
      "TP: 667\n",
      "FP: 471\n",
      "TN: 1267\n",
      "FN: 564\n",
      "\n",
      "Accuracy: 0.6513977770293028\n",
      "Precision: 0.5861159929701231\n",
      "Recall: 0.5418359057676686\n",
      "F-measure: 0.5631067961165049\n",
      "Precision-Recall AUC: 0.6056356912068408\n",
      "AUC: 0.6834732584303275\n",
      "MCC: 0.2744372153612606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import sklearn\n",
    "import random\n",
    "import clang\n",
    "from clang import *\n",
    "from clang import cindex\n",
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from tokenizers.pre_tokenizers import PreTokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers import NormalizedString,PreTokenizedString\n",
    "from typing import List\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import normalizers,decoders\n",
    "from tokenizers.normalizers import StripAccents, unicode_normalizer_from_str, Replace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers import processors,pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "# definitions\n",
    "class MyTokenizer:\n",
    "    cidx = cindex.Index.create()\n",
    "\n",
    "    def clang_split(self, i: int, normalized_string: NormalizedString) -> List[NormalizedString]:\n",
    "        ## Tokkenize using clang\n",
    "        tok = []\n",
    "        tu = self.cidx.parse('tmp.c',\n",
    "                       args=[''],  \n",
    "                       unsaved_files=[('tmp.c', str(normalized_string.original))],  \n",
    "                       options=0)\n",
    "        for t in tu.get_tokens(extent=tu.cursor.extent):\n",
    "            spelling = t.spelling.strip()\n",
    "            if spelling == '': continue\n",
    "            ## Keyword no need\n",
    "            ## Punctuations no need\n",
    "            ## Literal all to BPE\n",
    "            #spelling = spelling.replace(' ', '')\n",
    "            tok.append(NormalizedString(spelling))\n",
    "        return(tok)\n",
    "\n",
    "    def pre_tokenize(self, pretok: PreTokenizedString):\n",
    "        pretok.split(self.clang_split)\n",
    "\n",
    "def process_encodings(encodings):\n",
    "    input_ids=[]\n",
    "    attention_mask=[]\n",
    "    for enc in encodings:\n",
    "        input_ids.append(enc.ids)\n",
    "        attention_mask.append(enc.attention_mask)\n",
    "    return {'input_ids':input_ids, 'attention_mask':attention_mask}\n",
    "\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        assert len(self.encodings['input_ids']) == len(self.encodings['attention_mask']) ==  len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# tokenize and load dataset\n",
    "vocab, merges = BPE.read_file(vocab=\"./tokenizer/drapgh-vocab.json\", merges=\"./tokenizer/drapgh-merges.txt\")\n",
    "my_tokenizer = Tokenizer(BPE(vocab, merges, unk_token=\"<unk>\"))\n",
    "\n",
    "my_tokenizer.normalizer = normalizers.Sequence([StripAccents(), Replace(\" \", \"Ä\")])\n",
    "my_tokenizer.pre_tokenizer = PreTokenizer.custom(MyTokenizer())\n",
    "my_tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "my_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    special_tokens=[\n",
    "    (\"<s>\",0),\n",
    "    (\"<pad>\",1),\n",
    "    (\"</s>\",2),\n",
    "    (\"<unk>\",3),\n",
    "    (\"<mask>\",4)\n",
    "    ]\n",
    ")\n",
    "\n",
    "my_tokenizer.enable_truncation(max_length=1024)\n",
    "my_tokenizer.enable_padding(direction='right', pad_id=1, pad_type_id=0, pad_token='<pad>', length=None, pad_to_multiple_of=None)\n",
    "\n",
    "m1 = pd.read_json(init_train_path)\n",
    "m2 = pd.read_json(init_val_path)\n",
    "\n",
    "train_encodings = my_tokenizer.encode_batch(m1.commit_patch)\n",
    "train_encodings = process_encodings(train_encodings)\n",
    "\n",
    "val_encodings = my_tokenizer.encode_batch(m2.commit_patch)\n",
    "val_encodings = process_encodings(val_encodings)\n",
    "\n",
    "train_dataset = MyCustomDataset(train_encodings, m1.label.tolist())\n",
    "val_dataset = MyCustomDataset(val_encodings, m2.label.tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# generate intermediate data by CodeTransformer\n",
    "model = RobertaForSequenceClassification.from_pretrained(finetuned_ct_model_path)\n",
    "model.to(device)\n",
    "\n",
    "def generate_ct_intermediate_dataset(data_loader, intermediate_data_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.nn.functional.softmax(outputs[0], dim=1).tolist()\n",
    "            assert(len(probs) == len(labels))\n",
    "            for i in range(len(probs)):\n",
    "                prob = probs[i]\n",
    "                label = int(labels[i])\n",
    "                content = '\\t'.join([str(i) for i in prob + [label]]) + '\\n'\n",
    "                write_to_file(content, intermediate_data_path)\n",
    "\n",
    "remove_file_if_exist(intermediate_ct_train_path)\n",
    "remove_file_if_exist(intermediate_ct_val_path)\n",
    "\n",
    "print('Generating codeTF intermediate dataset:')\n",
    "generate_ct_intermediate_dataset(train_loader, intermediate_ct_train_path)\n",
    "del train_loader\n",
    "generate_ct_intermediate_dataset(val_loader, intermediate_ct_val_path)\n",
    "del val_loader\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# evaluation\n",
    "print('\\nEvaluation:')\n",
    "model = RobertaForSequenceClassification.from_pretrained(finetuned_ct_model_path)\n",
    "\n",
    "test_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "def softmax_accuracy(probs,all_labels):\n",
    "    def getClass(x):\n",
    "        return(x.index(max(x)))\n",
    "\n",
    "    all_labels = all_labels.tolist()\n",
    "    probs = pd.Series(probs.tolist())\n",
    "    all_predicted = probs.apply(getClass)\n",
    "    all_predicted.reset_index(drop=True, inplace=True)\n",
    "    vc = pd.value_counts(all_predicted == all_labels)\n",
    "    try:\n",
    "        acc = vc[1]/len(all_labels)\n",
    "    except:\n",
    "        if(vc.index[0]==False):\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = 1\n",
    "    return(acc,all_predicted)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "all_pred=[]\n",
    "all_labels=[]\n",
    "all_probs=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        acc_val,pred = softmax_accuracy(torch.nn.functional.softmax(outputs[1],dim=1),labels)\n",
    "        all_pred += pred.tolist()\n",
    "        all_labels += labels.tolist()\n",
    "        all_probs += outputs[1].tolist()\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_pred)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "probs2=[]\n",
    "for x in all_probs:\n",
    "    probs2.append(x[1])\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=all_labels, y_pred=all_pred)))\n",
    "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=all_labels, y_pred=all_pred)))\n",
    "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=all_labels, y_pred=all_pred)))\n",
    "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=all_labels, y_pred=all_pred)))\n",
    "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=all_labels, y_score=probs2)))\n",
    "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=all_labels, y_score=probs2)))\n",
    "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=all_labels, y_pred=all_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MsgTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 70/70 [02:30<00:00,  2.15s/it]\n",
      "100%|██████████| 24/24 [00:50<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.9593    0.5834    0.7256      1738\n",
      "  vulnerable     0.6213    0.9651    0.7560      1231\n",
      "\n",
      "    accuracy                         0.7417      2969\n",
      "   macro avg     0.7903    0.7742    0.7408      2969\n",
      "weighted avg     0.8192    0.7417    0.7382      2969\n",
      "\n",
      "[[1014  724]\n",
      " [  43 1188]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from transformers import RobertaModel, RobertaTokenizerFast\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import os\n",
    "import random\n",
    "\n",
    "# definitions\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "BERT_CONFIG = 'roberta-large'\n",
    "labels = {0:0, 1:1}\n",
    "BATCH_SIZE = 128\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(BERT_CONFIG)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length=512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['commit_message']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ParallelConv(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dims, filters, dropout=0.5):\n",
    "        super().__init__()\n",
    "        convs = []        \n",
    "        self.output_dims = sum([t[1] for t in filters])\n",
    "        for (filter_length, output_dims) in filters:\n",
    "            pad = filter_length//2\n",
    "            conv = nn.Sequential(\n",
    "                nn.Conv1d(input_dims, output_dims, filter_length, padding=pad),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            convs.append(conv)\n",
    "        # Add the module so its managed correctly\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.conv_drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_bct):\n",
    "        mots = []\n",
    "        for conv in self.convs:\n",
    "            # In Conv1d, data BxCxT, max over time\n",
    "            conv_out = conv(input_bct)\n",
    "            mot, _ = conv_out.max(2)\n",
    "            mots.append(mot)\n",
    "        mots = torch.cat(mots, 1)\n",
    "        return self.conv_drop(mots)\n",
    "\n",
    "class ConvClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dims,\n",
    "                 filters=[(2, 100), (3, 100), (4, 100)],\n",
    "                 dropout=0.5, hidden_units=[]):\n",
    "        super().__init__()\n",
    "        self.bert = RobertaModel.from_pretrained(BERT_CONFIG)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.convs = ParallelConv(embed_dims, filters, dropout)\n",
    "        \n",
    "        input_units = self.convs.output_dims\n",
    "        output_units = self.convs.output_dims\n",
    "        sequence = []\n",
    "        for h in hidden_units:\n",
    "            sequence.append(self.dropout(nn.Linear(input_units, h)))\n",
    "            input_units = h\n",
    "            output_units = h\n",
    "            \n",
    "        sequence.append(nn.Linear(output_units, 2))\n",
    "        self.outputs = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        x, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        embed = self.dropout(x)\n",
    "        embed = embed.transpose(1, 2).contiguous()\n",
    "        hidden = self.convs(embed)\n",
    "        linear = self.outputs(hidden)\n",
    "        return F.log_softmax(linear, dim=-1)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# generate intermediate data by MsgTransformer\n",
    "embed_dim = 1024\n",
    "model = ConvClassifier(embed_dim)\n",
    "model.load_state_dict(torch.load(finetuned_mt_model_path))\n",
    "model.to(device)\n",
    "\n",
    "def generate_mt_intermediate_dataset(input_data, intermediate_data_path):\n",
    "    data_loader = torch.utils.data.DataLoader(Dataset(input_data), batch_size=BATCH_SIZE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader):\n",
    "            labels = labels.to(device)\n",
    "            masks = texts['attention_mask'].to(device)\n",
    "            input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "            outputs = model(input_ids, masks)\n",
    "\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1).tolist()\n",
    "            assert(len(probs) == len(labels))\n",
    "            for i in range(len(probs)):\n",
    "                prob = probs[i]\n",
    "                label = int(labels[i])\n",
    "                content = '\\t'.join([str(i) for i in prob + [label]]) + '\\n'\n",
    "                write_to_file(content, intermediate_data_path)\n",
    "\n",
    "df_train = pd.read_json(init_train_path)\n",
    "df_val = pd.read_json(init_val_path)\n",
    "\n",
    "remove_file_if_exist(intermediate_mt_train_path)\n",
    "remove_file_if_exist(intermediate_mt_val_path)\n",
    "\n",
    "generate_mt_intermediate_dataset(df_train, intermediate_mt_train_path)\n",
    "generate_mt_intermediate_dataset(df_val, intermediate_mt_val_path)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# evaluation\n",
    "print('\\nEvaluation:')\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    total_acc_test = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "            test_label = test_label.data.cpu().numpy()\n",
    "            predic = output.argmax(dim=1).data.cpu().numpy()\n",
    "            labels_all = np.append(labels_all, test_label)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    report = metrics.classification_report(labels_all, predict_all, target_names=['benign', 'vulnerable'], digits=4)\n",
    "    confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .4f}')\n",
    "    print(report)\n",
    "    print(confusion)\n",
    "\n",
    "embed_dim = 1024\n",
    "model = ConvClassifier(embed_dim)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(finetuned_mt_model_path))\n",
    "evaluate(model, df_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine everything into intermediate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_train_path = f'{intermediate_directory}/train.txt'\n",
    "intermediate_val_path = f'{intermediate_directory}/val.txt'\n",
    "\n",
    "def generate_intermediate_dataset(intermediate_mt_data_path, intermediate_ct_data_path, intermediate_data_path):\n",
    "    with open(intermediate_mt_data_path) as f:\n",
    "        mt_data_list = f.read().split('\\n')\n",
    "    \n",
    "    with open(intermediate_ct_data_path) as f:\n",
    "        ct_data_list = f.read().split('\\n')\n",
    "    \n",
    "    mt_data_list = mt_data_list[:-1] if not mt_data_list[-1] else mt_data_list\n",
    "    ct_data_list = ct_data_list[:-1] if not ct_data_list[-1] else ct_data_list\n",
    "\n",
    "    assert(len(mt_data_list) == len(ct_data_list))\n",
    "    \n",
    "    for i in range(len(mt_data_list)):\n",
    "        mt_data = mt_data_list[i].split('\\t')\n",
    "        ct_data = ct_data_list[i].split('\\t')\n",
    "        assert(mt_data[2] == ct_data[2])\n",
    "        label = mt_data[2]\n",
    "        content = '\\t'.join(mt_data[:2] + ct_data[:2] + [label])\n",
    "        content = content + '\\n' if i < len(mt_data_list) - 1 else content\n",
    "        write_to_file(content, intermediate_data_path)\n",
    "\n",
    "remove_file_if_exist(intermediate_train_path)\n",
    "remove_file_if_exist(intermediate_val_path)\n",
    "\n",
    "generate_intermediate_dataset(intermediate_mt_train_path, intermediate_ct_train_path, intermediate_train_path)\n",
    "generate_intermediate_dataset(intermediate_mt_val_path, intermediate_ct_val_path, intermediate_val_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 515.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.1511             | Train Accuracy:  0.7834             | Val Loss:  0.1548             | Val Accuracy:  0.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 667.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.1501             | Train Accuracy:  0.7679             | Val Loss:  0.1543             | Val Accuracy:  0.7194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 677.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.1494             | Train Accuracy:  0.7694             | Val Loss:  0.1537             | Val Accuracy:  0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 613.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.1486             | Train Accuracy:  0.7705             | Val Loss:  0.1532             | Val Accuracy:  0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 538.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.1479             | Train Accuracy:  0.7717             | Val Loss:  0.1526             | Val Accuracy:  0.7252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 584.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.1472             | Train Accuracy:  0.7726             | Val Loss:  0.1521             | Val Accuracy:  0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 684.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.1465             | Train Accuracy:  0.7737             | Val Loss:  0.1515             | Val Accuracy:  0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 683.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.1458             | Train Accuracy:  0.7750             | Val Loss:  0.1509             | Val Accuracy:  0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 682.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.1451             | Train Accuracy:  0.7769             | Val Loss:  0.1504             | Val Accuracy:  0.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 687.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.1444             | Train Accuracy:  0.7781             | Val Loss:  0.1498             | Val Accuracy:  0.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 682.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss:  0.1437             | Train Accuracy:  0.7787             | Val Loss:  0.1493             | Val Accuracy:  0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 589.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 | Train Loss:  0.1430             | Train Accuracy:  0.7801             | Val Loss:  0.1487             | Val Accuracy:  0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 686.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 | Train Loss:  0.1422             | Train Accuracy:  0.7808             | Val Loss:  0.1482             | Val Accuracy:  0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 586.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 14 | Train Loss:  0.1415             | Train Accuracy:  0.7823             | Val Loss:  0.1476             | Val Accuracy:  0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 572.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 | Train Loss:  0.1408             | Train Accuracy:  0.7836             | Val Loss:  0.1470             | Val Accuracy:  0.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 663.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 16 | Train Loss:  0.1401             | Train Accuracy:  0.7852             | Val Loss:  0.1465             | Val Accuracy:  0.7369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 622.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 17 | Train Loss:  0.1393             | Train Accuracy:  0.7867             | Val Loss:  0.1459             | Val Accuracy:  0.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 518.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 18 | Train Loss:  0.1386             | Train Accuracy:  0.7883             | Val Loss:  0.1453             | Val Accuracy:  0.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 523.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 19 | Train Loss:  0.1379             | Train Accuracy:  0.7895             | Val Loss:  0.1448             | Val Accuracy:  0.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 541.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20 | Train Loss:  0.1371             | Train Accuracy:  0.7903             | Val Loss:  0.1442             | Val Accuracy:  0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 655.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 21 | Train Loss:  0.1364             | Train Accuracy:  0.7923             | Val Loss:  0.1436             | Val Accuracy:  0.7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 688.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 22 | Train Loss:  0.1356             | Train Accuracy:  0.7977             | Val Loss:  0.1431             | Val Accuracy:  0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 23 | Train Loss:  0.1349             | Train Accuracy:  0.8038             | Val Loss:  0.1425             | Val Accuracy:  0.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 689.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 24 | Train Loss:  0.1342             | Train Accuracy:  0.8101             | Val Loss:  0.1419             | Val Accuracy:  0.7592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 633.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 25 | Train Loss:  0.1334             | Train Accuracy:  0.8152             | Val Loss:  0.1413             | Val Accuracy:  0.7639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 623.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 26 | Train Loss:  0.1327             | Train Accuracy:  0.8193             | Val Loss:  0.1408             | Val Accuracy:  0.7676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 683.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 27 | Train Loss:  0.1319             | Train Accuracy:  0.8229             | Val Loss:  0.1402             | Val Accuracy:  0.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 690.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 28 | Train Loss:  0.1312             | Train Accuracy:  0.8281             | Val Loss:  0.1396             | Val Accuracy:  0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 691.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 29 | Train Loss:  0.1304             | Train Accuracy:  0.8324             | Val Loss:  0.1390             | Val Accuracy:  0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 573.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30 | Train Loss:  0.1297             | Train Accuracy:  0.8354             | Val Loss:  0.1385             | Val Accuracy:  0.7760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 654.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 31 | Train Loss:  0.1289             | Train Accuracy:  0.8398             | Val Loss:  0.1379             | Val Accuracy:  0.7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 676.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 32 | Train Loss:  0.1282             | Train Accuracy:  0.8438             | Val Loss:  0.1373             | Val Accuracy:  0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 604.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 33 | Train Loss:  0.1274             | Train Accuracy:  0.8461             | Val Loss:  0.1367             | Val Accuracy:  0.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 544.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 34 | Train Loss:  0.1266             | Train Accuracy:  0.8501             | Val Loss:  0.1362             | Val Accuracy:  0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 603.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 35 | Train Loss:  0.1259             | Train Accuracy:  0.8529             | Val Loss:  0.1356             | Val Accuracy:  0.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 539.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 36 | Train Loss:  0.1251             | Train Accuracy:  0.8565             | Val Loss:  0.1350             | Val Accuracy:  0.7945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 667.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 37 | Train Loss:  0.1244             | Train Accuracy:  0.8591             | Val Loss:  0.1344             | Val Accuracy:  0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 677.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 38 | Train Loss:  0.1236             | Train Accuracy:  0.8613             | Val Loss:  0.1339             | Val Accuracy:  0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 681.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 39 | Train Loss:  0.1228             | Train Accuracy:  0.8644             | Val Loss:  0.1333             | Val Accuracy:  0.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 694.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 40 | Train Loss:  0.1221             | Train Accuracy:  0.8673             | Val Loss:  0.1327             | Val Accuracy:  0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 679.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 41 | Train Loss:  0.1213             | Train Accuracy:  0.8701             | Val Loss:  0.1321             | Val Accuracy:  0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 667.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 42 | Train Loss:  0.1206             | Train Accuracy:  0.8731             | Val Loss:  0.1316             | Val Accuracy:  0.8094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 646.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 43 | Train Loss:  0.1198             | Train Accuracy:  0.8760             | Val Loss:  0.1310             | Val Accuracy:  0.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 580.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 44 | Train Loss:  0.1191             | Train Accuracy:  0.8784             | Val Loss:  0.1304             | Val Accuracy:  0.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 625.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 45 | Train Loss:  0.1183             | Train Accuracy:  0.8801             | Val Loss:  0.1299             | Val Accuracy:  0.8164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 671.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 46 | Train Loss:  0.1176             | Train Accuracy:  0.8824             | Val Loss:  0.1293             | Val Accuracy:  0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 672.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 47 | Train Loss:  0.1168             | Train Accuracy:  0.8843             | Val Loss:  0.1288             | Val Accuracy:  0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 687.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 48 | Train Loss:  0.1161             | Train Accuracy:  0.8865             | Val Loss:  0.1282             | Val Accuracy:  0.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 611.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 49 | Train Loss:  0.1153             | Train Accuracy:  0.8887             | Val Loss:  0.1276             | Val Accuracy:  0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 690.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50 | Train Loss:  0.1146             | Train Accuracy:  0.8903             | Val Loss:  0.1271             | Val Accuracy:  0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 569.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 51 | Train Loss:  0.1139             | Train Accuracy:  0.8920             | Val Loss:  0.1265             | Val Accuracy:  0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 643.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 52 | Train Loss:  0.1131             | Train Accuracy:  0.8934             | Val Loss:  0.1260             | Val Accuracy:  0.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 690.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 53 | Train Loss:  0.1124             | Train Accuracy:  0.8952             | Val Loss:  0.1254             | Val Accuracy:  0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 687.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 54 | Train Loss:  0.1117             | Train Accuracy:  0.8958             | Val Loss:  0.1249             | Val Accuracy:  0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 636.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 55 | Train Loss:  0.1109             | Train Accuracy:  0.8966             | Val Loss:  0.1244             | Val Accuracy:  0.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 633.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 56 | Train Loss:  0.1102             | Train Accuracy:  0.8978             | Val Loss:  0.1238             | Val Accuracy:  0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 609.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 57 | Train Loss:  0.1095             | Train Accuracy:  0.8985             | Val Loss:  0.1233             | Val Accuracy:  0.8377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 581.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 58 | Train Loss:  0.1087             | Train Accuracy:  0.8988             | Val Loss:  0.1227             | Val Accuracy:  0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 553.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 59 | Train Loss:  0.1080             | Train Accuracy:  0.9001             | Val Loss:  0.1222             | Val Accuracy:  0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 573.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 60 | Train Loss:  0.1073             | Train Accuracy:  0.9010             | Val Loss:  0.1217             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 496.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 61 | Train Loss:  0.1066             | Train Accuracy:  0.9020             | Val Loss:  0.1212             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 487.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 62 | Train Loss:  0.1059             | Train Accuracy:  0.9030             | Val Loss:  0.1206             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 513.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 63 | Train Loss:  0.1052             | Train Accuracy:  0.9041             | Val Loss:  0.1201             | Val Accuracy:  0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 569.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 64 | Train Loss:  0.1044             | Train Accuracy:  0.9046             | Val Loss:  0.1196             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 588.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 65 | Train Loss:  0.1037             | Train Accuracy:  0.9056             | Val Loss:  0.1191             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 615.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 66 | Train Loss:  0.1030             | Train Accuracy:  0.9064             | Val Loss:  0.1186             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 622.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 67 | Train Loss:  0.1024             | Train Accuracy:  0.9067             | Val Loss:  0.1181             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 591.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 68 | Train Loss:  0.1017             | Train Accuracy:  0.9077             | Val Loss:  0.1176             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 655.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 69 | Train Loss:  0.1010             | Train Accuracy:  0.9083             | Val Loss:  0.1171             | Val Accuracy:  0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 653.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 70 | Train Loss:  0.1003             | Train Accuracy:  0.9083             | Val Loss:  0.1166             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 611.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 71 | Train Loss:  0.0996             | Train Accuracy:  0.9092             | Val Loss:  0.1161             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 676.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 72 | Train Loss:  0.0989             | Train Accuracy:  0.9096             | Val Loss:  0.1156             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 624.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 73 | Train Loss:  0.0983             | Train Accuracy:  0.9095             | Val Loss:  0.1151             | Val Accuracy:  0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 628.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 74 | Train Loss:  0.0976             | Train Accuracy:  0.9102             | Val Loss:  0.1147             | Val Accuracy:  0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 617.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 75 | Train Loss:  0.0970             | Train Accuracy:  0.9103             | Val Loss:  0.1142             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 650.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 76 | Train Loss:  0.0963             | Train Accuracy:  0.9112             | Val Loss:  0.1137             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 77 | Train Loss:  0.0957             | Train Accuracy:  0.9115             | Val Loss:  0.1133             | Val Accuracy:  0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 507.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 78 | Train Loss:  0.0950             | Train Accuracy:  0.9117             | Val Loss:  0.1128             | Val Accuracy:  0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 662.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 79 | Train Loss:  0.0944             | Train Accuracy:  0.9115             | Val Loss:  0.1124             | Val Accuracy:  0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 80 | Train Loss:  0.0937             | Train Accuracy:  0.9115             | Val Loss:  0.1119             | Val Accuracy:  0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 81 | Train Loss:  0.0931             | Train Accuracy:  0.9120             | Val Loss:  0.1115             | Val Accuracy:  0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 665.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 82 | Train Loss:  0.0925             | Train Accuracy:  0.9123             | Val Loss:  0.1111             | Val Accuracy:  0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 667.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 83 | Train Loss:  0.0919             | Train Accuracy:  0.9119             | Val Loss:  0.1106             | Val Accuracy:  0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 524.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 84 | Train Loss:  0.0913             | Train Accuracy:  0.9117             | Val Loss:  0.1102             | Val Accuracy:  0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 544.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 85 | Train Loss:  0.0907             | Train Accuracy:  0.9119             | Val Loss:  0.1098             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 648.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 86 | Train Loss:  0.0901             | Train Accuracy:  0.9115             | Val Loss:  0.1094             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 562.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 87 | Train Loss:  0.0895             | Train Accuracy:  0.9116             | Val Loss:  0.1090             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 556.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 88 | Train Loss:  0.0889             | Train Accuracy:  0.9112             | Val Loss:  0.1086             | Val Accuracy:  0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 527.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 89 | Train Loss:  0.0883             | Train Accuracy:  0.9114             | Val Loss:  0.1082             | Val Accuracy:  0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 673.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 90 | Train Loss:  0.0878             | Train Accuracy:  0.9115             | Val Loss:  0.1078             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 91 | Train Loss:  0.0872             | Train Accuracy:  0.9120             | Val Loss:  0.1074             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 595.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 92 | Train Loss:  0.0867             | Train Accuracy:  0.9124             | Val Loss:  0.1071             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 592.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 93 | Train Loss:  0.0861             | Train Accuracy:  0.9124             | Val Loss:  0.1067             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 672.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 94 | Train Loss:  0.0856             | Train Accuracy:  0.9124             | Val Loss:  0.1063             | Val Accuracy:  0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 683.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 95 | Train Loss:  0.0851             | Train Accuracy:  0.9124             | Val Loss:  0.1060             | Val Accuracy:  0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 96 | Train Loss:  0.0845             | Train Accuracy:  0.9124             | Val Loss:  0.1056             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 680.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 97 | Train Loss:  0.0840             | Train Accuracy:  0.9128             | Val Loss:  0.1053             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 688.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 98 | Train Loss:  0.0835             | Train Accuracy:  0.9126             | Val Loss:  0.1049             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 691.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 99 | Train Loss:  0.0830             | Train Accuracy:  0.9131             | Val Loss:  0.1046             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 672.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 100 | Train Loss:  0.0825             | Train Accuracy:  0.9134             | Val Loss:  0.1043             | Val Accuracy:  0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 665.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 101 | Train Loss:  0.0820             | Train Accuracy:  0.9133             | Val Loss:  0.1040             | Val Accuracy:  0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 647.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 102 | Train Loss:  0.0815             | Train Accuracy:  0.9133             | Val Loss:  0.1036             | Val Accuracy:  0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 676.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 103 | Train Loss:  0.0811             | Train Accuracy:  0.9133             | Val Loss:  0.1033             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 677.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 104 | Train Loss:  0.0806             | Train Accuracy:  0.9138             | Val Loss:  0.1030             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 680.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 105 | Train Loss:  0.0801             | Train Accuracy:  0.9139             | Val Loss:  0.1027             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 682.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 106 | Train Loss:  0.0797             | Train Accuracy:  0.9139             | Val Loss:  0.1024             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 574.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 107 | Train Loss:  0.0792             | Train Accuracy:  0.9137             | Val Loss:  0.1022             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 108 | Train Loss:  0.0788             | Train Accuracy:  0.9139             | Val Loss:  0.1019             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 539.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 109 | Train Loss:  0.0784             | Train Accuracy:  0.9135             | Val Loss:  0.1016             | Val Accuracy:  0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 527.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 110 | Train Loss:  0.0779             | Train Accuracy:  0.9135             | Val Loss:  0.1013             | Val Accuracy:  0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 503.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 111 | Train Loss:  0.0775             | Train Accuracy:  0.9135             | Val Loss:  0.1010             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 533.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 112 | Train Loss:  0.0771             | Train Accuracy:  0.9138             | Val Loss:  0.1008             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 113 | Train Loss:  0.0767             | Train Accuracy:  0.9139             | Val Loss:  0.1005             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 620.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 114 | Train Loss:  0.0763             | Train Accuracy:  0.9140             | Val Loss:  0.1003             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 677.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 115 | Train Loss:  0.0759             | Train Accuracy:  0.9140             | Val Loss:  0.1000             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 673.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 116 | Train Loss:  0.0755             | Train Accuracy:  0.9138             | Val Loss:  0.0998             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 673.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 117 | Train Loss:  0.0751             | Train Accuracy:  0.9138             | Val Loss:  0.0995             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 610.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 118 | Train Loss:  0.0747             | Train Accuracy:  0.9142             | Val Loss:  0.0993             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 658.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 119 | Train Loss:  0.0743             | Train Accuracy:  0.9142             | Val Loss:  0.0991             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 671.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 120 | Train Loss:  0.0740             | Train Accuracy:  0.9141             | Val Loss:  0.0989             | Val Accuracy:  0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 121 | Train Loss:  0.0736             | Train Accuracy:  0.9146             | Val Loss:  0.0986             | Val Accuracy:  0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 578.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 122 | Train Loss:  0.0732             | Train Accuracy:  0.9148             | Val Loss:  0.0984             | Val Accuracy:  0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 522.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 123 | Train Loss:  0.0729             | Train Accuracy:  0.9148             | Val Loss:  0.0982             | Val Accuracy:  0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 621.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 124 | Train Loss:  0.0725             | Train Accuracy:  0.9149             | Val Loss:  0.0980             | Val Accuracy:  0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 631.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 125 | Train Loss:  0.0722             | Train Accuracy:  0.9151             | Val Loss:  0.0978             | Val Accuracy:  0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 597.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 126 | Train Loss:  0.0719             | Train Accuracy:  0.9152             | Val Loss:  0.0976             | Val Accuracy:  0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 671.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 127 | Train Loss:  0.0715             | Train Accuracy:  0.9150             | Val Loss:  0.0974             | Val Accuracy:  0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 605.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 128 | Train Loss:  0.0712             | Train Accuracy:  0.9155             | Val Loss:  0.0972             | Val Accuracy:  0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 553.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 129 | Train Loss:  0.0709             | Train Accuracy:  0.9155             | Val Loss:  0.0971             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 675.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 130 | Train Loss:  0.0706             | Train Accuracy:  0.9153             | Val Loss:  0.0969             | Val Accuracy:  0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 674.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 131 | Train Loss:  0.0703             | Train Accuracy:  0.9152             | Val Loss:  0.0967             | Val Accuracy:  0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 599.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 132 | Train Loss:  0.0700             | Train Accuracy:  0.9152             | Val Loss:  0.0965             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 572.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 133 | Train Loss:  0.0697             | Train Accuracy:  0.9152             | Val Loss:  0.0964             | Val Accuracy:  0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 595.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 134 | Train Loss:  0.0694             | Train Accuracy:  0.9151             | Val Loss:  0.0962             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 696.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 135 | Train Loss:  0.0691             | Train Accuracy:  0.9151             | Val Loss:  0.0961             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 690.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 136 | Train Loss:  0.0688             | Train Accuracy:  0.9151             | Val Loss:  0.0959             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 606.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 137 | Train Loss:  0.0685             | Train Accuracy:  0.9152             | Val Loss:  0.0957             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:04<00:00, 553.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 138 | Train Loss:  0.0683             | Train Accuracy:  0.9151             | Val Loss:  0.0956             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 680.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 139 | Train Loss:  0.0680             | Train Accuracy:  0.9152             | Val Loss:  0.0955             | Val Accuracy:  0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 688.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 140 | Train Loss:  0.0677             | Train Accuracy:  0.9151             | Val Loss:  0.0953             | Val Accuracy:  0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 687.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 141 | Train Loss:  0.0675             | Train Accuracy:  0.9149             | Val Loss:  0.0952             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 691.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 142 | Train Loss:  0.0672             | Train Accuracy:  0.9151             | Val Loss:  0.0950             | Val Accuracy:  0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 697.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 143 | Train Loss:  0.0670             | Train Accuracy:  0.9152             | Val Loss:  0.0949             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 694.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 144 | Train Loss:  0.0667             | Train Accuracy:  0.9149             | Val Loss:  0.0948             | Val Accuracy:  0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 611.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 145 | Train Loss:  0.0665             | Train Accuracy:  0.9147             | Val Loss:  0.0946             | Val Accuracy:  0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 660.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 146 | Train Loss:  0.0662             | Train Accuracy:  0.9148             | Val Loss:  0.0945             | Val Accuracy:  0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 615.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 147 | Train Loss:  0.0660             | Train Accuracy:  0.9148             | Val Loss:  0.0944             | Val Accuracy:  0.8393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 678.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 148 | Train Loss:  0.0658             | Train Accuracy:  0.9149             | Val Loss:  0.0943             | Val Accuracy:  0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 692.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 149 | Train Loss:  0.0655             | Train Accuracy:  0.9149             | Val Loss:  0.0942             | Val Accuracy:  0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2227/2227 [00:03<00:00, 656.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 150 | Train Loss:  0.0653             | Train Accuracy:  0.9149             | Val Loss:  0.0941             | Val Accuracy:  0.8377\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "EPOCHS = 150\n",
    "LR = 1e-6\n",
    "BATCH_SIZE = 4\n",
    "intermediate_train_path = f'{intermediate_directory}/train.txt'\n",
    "intermediate_val_path = f'{intermediate_directory}/val.txt'\n",
    "MODEL_SAVE_PATH = f'{root_directory}/ensemble_model/{DATASET_MASKING}{DATASET_NAME}'\n",
    "remove_file_if_exist(MODEL_SAVE_PATH)\n",
    "mkdir_if_not_exist(MODEL_SAVE_PATH)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path) as f:\n",
    "            data_list = f.read().split('\\n')\n",
    "        self.labels = [ int(data.split('\\t')[-1]) for data in data_list ]\n",
    "        self.inputs = [ [float(v) for v in data.split('\\t')[:-1]] for data in data_list ]\n",
    "        assert(len(self.labels) == len(self.inputs))\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x[0], x[1], x[2], x[3], y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(input_dim, 20)\n",
    "        self.out = nn.Linear(20, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def train(model, train_dataset, val_dataset):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        for x1, x2, x3, x4, y in tqdm(train_dataloader):\n",
    "            x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x1, x2, x3, x4, y in val_dataloader:\n",
    "                x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y)\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "                acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .4f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_dataset): .4f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_dataset): .4f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_dataset): .4f}')\n",
    "\n",
    "        val_acc = f'{total_acc_val / len(val_dataset):.4f}'\n",
    "        torch.save(model.state_dict(), f'{MODEL_SAVE_PATH}/ensemble2_cnn_{val_acc}_epoch{epoch_num + 1}.pt')\n",
    "\n",
    "train_dataset = MyDataset(intermediate_train_path)\n",
    "val_dataset = MyDataset(intermediate_val_path)\n",
    "test_dataset = val_dataset\n",
    "\n",
    "model = MLP(4, 2)\n",
    "train(model, train_dataset, val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.8414    0.9068    0.8729      1738\n",
      "  vulnerable     0.8522    0.7587    0.8028      1231\n",
      "\n",
      "    accuracy                         0.8454      2969\n",
      "   macro avg     0.8468    0.8328    0.8378      2969\n",
      "weighted avg     0.8459    0.8454    0.8438      2969\n",
      "\n",
      "[[1576  162]\n",
      " [ 297  934]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_dataset):\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, x4, y in test_dataloader:\n",
    "            x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            y = y.data.cpu().numpy()\n",
    "            predic = y_pred.argmax(dim=1).data.cpu().numpy()\n",
    "            labels_all = np.append(labels_all, y)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    report = metrics.classification_report(labels_all, predict_all, target_names=['benign', 'vulnerable'], digits=4)\n",
    "    confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_dataset): .4f}')\n",
    "    print(report)\n",
    "    print(confusion)\n",
    "\n",
    "MODEL_SAVE_PATH = f'{root_directory}/ensemble_model/{DATASET_MASKING}{DATASET_NAME}'\n",
    "\n",
    "mkdir_if_not_exist(MODEL_SAVE_PATH)\n",
    "model = MLP(4, 2)\n",
    "saved_model_name = 'ensemble2_cnn_0.8454_epoch109.pt'\n",
    "model.load_state_dict(torch.load(f'{MODEL_SAVE_PATH}/{saved_model_name}'))\n",
    "evaluate(model, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
