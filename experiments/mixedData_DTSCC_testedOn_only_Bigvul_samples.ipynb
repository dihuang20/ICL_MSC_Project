{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# This source code file refers to:\n",
    "# https://github.com/ICL-ml4csec/VulBERTa\n",
    "# https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "# https://huggingface.co/docs/transformers/model_doc/roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def write_to_file(text, path, mode='a'): # 'a': append; 'w': overwrite\n",
    "    with open(path, mode) as f:\n",
    "        f.write(text)\n",
    "\n",
    "def mkdir_if_not_exist(directory):\n",
    "    if not directory: return\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "def remove_file_if_exist(path):\n",
    "    if not path: return\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            shutil.rmtree(path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using', device)\n",
    "\n",
    "# The following randomization refers to: https://github.com/ICL-ml4csec/VulBERTa/blob/main/Finetuning_VulBERTa-MLP.ipynb\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "# -------------------------------------- start\n",
    "\n",
    "DATASET_NAME = 'combined'\n",
    "# DATASET_MASKING = 'masked_'\n",
    "DATASET_MASKING = ''\n",
    "\n",
    "codeTF_check_point = 'vulberta_ 0.6865_ep2.pt'\n",
    "msgTF_check_point = 'roberta_base_fc_0.9767_ep9(combined).pt'\n",
    "\n",
    "# -------------------------------------- end\n",
    "\n",
    "pretrained_model_path = '/root/autodl-tmp/VulBERTa/'\n",
    "\n",
    "root_directory = '/root/autodl-tmp'\n",
    "dataset_directory = f'{root_directory}/output_dataset_1/{DATASET_MASKING}{DATASET_NAME}'\n",
    "init_train_path = f'{dataset_directory}/train.json'\n",
    "init_val_path = f'{dataset_directory}/val.json'\n",
    "init_test_path = f'{dataset_directory}/test.json'\n",
    "intermediate_directory = f'{root_directory}/intermediate/{DATASET_MASKING}{DATASET_NAME}'\n",
    "mkdir_if_not_exist(f'{root_directory}/intermediate')\n",
    "mkdir_if_not_exist(intermediate_directory)\n",
    "\n",
    "finetuned_ct_model_path = f'{root_directory}/codeTF_check_point/{DATASET_MASKING}{DATASET_NAME}/{codeTF_check_point}'\n",
    "intermediate_ct_train_path = f'{intermediate_directory}/ct_train.txt'\n",
    "intermediate_ct_val_path = f'{intermediate_directory}/ct_val.txt'\n",
    "intermediate_ct_test_path = f'{intermediate_directory}/ct_test.txt'\n",
    "\n",
    "finetuned_mt_model_path = f'{root_directory}/msgTF_check_point/{DATASET_MASKING}{DATASET_NAME}/{msgTF_check_point}'\n",
    "intermediate_mt_train_path = f'{intermediate_directory}/mt_train.txt'\n",
    "intermediate_mt_val_path = f'{intermediate_directory}/mt_val.txt'\n",
    "intermediate_mt_test_path = f'{intermediate_directory}/mt_test.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CodeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import sklearn\n",
    "import random\n",
    "import clang\n",
    "from clang import *\n",
    "from clang import cindex\n",
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from tokenizers.pre_tokenizers import PreTokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers import NormalizedString,PreTokenizedString\n",
    "from typing import List\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import normalizers,decoders\n",
    "from tokenizers.normalizers import StripAccents, unicode_normalizer_from_str, Replace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers import processors,pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "from sklearn import metrics\n",
    "\n",
    "# definitions\n",
    "class MyTokenizer:\n",
    "    cidx = cindex.Index.create()\n",
    "\n",
    "    def clang_split(self, i: int, normalized_string: NormalizedString) -> List[NormalizedString]:\n",
    "        ## Tokkenize using clang\n",
    "        tok = []\n",
    "        tu = self.cidx.parse('tmp.c',\n",
    "                       args=[''],  \n",
    "                       unsaved_files=[('tmp.c', str(normalized_string.original))],  \n",
    "                       options=0)\n",
    "        for t in tu.get_tokens(extent=tu.cursor.extent):\n",
    "            spelling = t.spelling.strip()\n",
    "            if spelling == '': continue\n",
    "            ## Keyword no need\n",
    "            ## Punctuations no need\n",
    "            ## Literal all to BPE\n",
    "            #spelling = spelling.replace(' ', '')\n",
    "            tok.append(NormalizedString(spelling))\n",
    "        return(tok)\n",
    "\n",
    "    def pre_tokenize(self, pretok: PreTokenizedString):\n",
    "        pretok.split(self.clang_split)\n",
    "\n",
    "def process_encodings(encodings):\n",
    "    input_ids=[]\n",
    "    attention_mask=[]\n",
    "    for enc in encodings:\n",
    "        input_ids.append(enc.ids)\n",
    "        attention_mask.append(enc.attention_mask)\n",
    "    return {'input_ids':input_ids, 'attention_mask':attention_mask}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# tokenize and load dataset\n",
    "print('Tokenizing dataset...')\n",
    "vocab, merges = BPE.read_file(vocab=\"./tokenizer/drapgh-vocab.json\", merges=\"./tokenizer/drapgh-merges.txt\")\n",
    "my_tokenizer = Tokenizer(BPE(vocab, merges, unk_token=\"<unk>\"))\n",
    "\n",
    "my_tokenizer.normalizer = normalizers.Sequence([StripAccents(), Replace(\" \", \"Ä\")])\n",
    "my_tokenizer.pre_tokenizer = PreTokenizer.custom(MyTokenizer())\n",
    "my_tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "my_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    special_tokens=[\n",
    "    (\"<s>\",0),\n",
    "    (\"<pad>\",1),\n",
    "    (\"</s>\",2),\n",
    "    (\"<unk>\",3),\n",
    "    (\"<mask>\",4)\n",
    "    ]\n",
    ")\n",
    "\n",
    "my_tokenizer.enable_truncation(max_length=1024)\n",
    "my_tokenizer.enable_padding(direction='right', pad_id=1, pad_type_id=0, pad_token='<pad>', length=None, pad_to_multiple_of=None)\n",
    "\n",
    "m1 = pd.read_json(init_train_path)\n",
    "m2 = pd.read_json(init_val_path)\n",
    "\n",
    "train_encodings = my_tokenizer.encode_batch(m1.commit_patch)\n",
    "train_encodings = process_encodings(train_encodings)\n",
    "\n",
    "val_encodings = my_tokenizer.encode_batch(m2.commit_patch)\n",
    "val_encodings = process_encodings(val_encodings)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, ids, encodings, labels):\n",
    "        self.ids = ids\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        assert len(self.encodings['input_ids']) == len(self.encodings['attention_mask']) == len(self.labels) == len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['ids'] = self.ids[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyCustomDataset(m1.id.tolist(), train_encodings, m1.label.tolist())\n",
    "val_dataset = MyCustomDataset(m2.id.tolist(), val_encodings, m2.label.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating intermediate data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-tmp/VulBERTa/ were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/VulBERTa/ and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 148/148 [04:28<00:00,  1.81s/it]\n",
      "100%|██████████| 37/37 [01:07<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.6913    0.6898    0.6906      2389\n",
      "  vulnerable     0.6816    0.6830    0.6823      2322\n",
      "\n",
      "    accuracy                         0.6865      4711\n",
      "   macro avg     0.6864    0.6864    0.6864      4711\n",
      "weighted avg     0.6865    0.6865    0.6865      4711\n",
      "\n",
      "[[1648  741]\n",
      " [ 736 1586]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# generate intermediate data by CodeTransformer\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Generating intermediate data...')\n",
    "model = RobertaForSequenceClassification.from_pretrained(pretrained_model_path)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(finetuned_ct_model_path))\n",
    "\n",
    "def generate_ct_intermediate_dataset(input_data, intermediate_data_path, evaluate=True):\n",
    "    data_loader = DataLoader(input_data, batch_size=128)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    total_acc = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            ids = batch['ids']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            # outputs['logits'] is equal to outputs[0]\n",
    "            outputs = outputs['logits']\n",
    "\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1).tolist()\n",
    "            assert(len(probs) == len(labels))\n",
    "            pred_list = outputs.argmax(dim=1).data.cpu().numpy().tolist()\n",
    "            for i in range(len(probs)):\n",
    "                id_ = ids[i]\n",
    "                prob = probs[i]\n",
    "                label = int(labels[i])\n",
    "                pred_ = int(pred_list[i])\n",
    "                content = '\\t'.join([str(i) for i in [id_] + prob + [pred_] + [label]]) + '\\n'\n",
    "                write_to_file(content, intermediate_data_path)\n",
    "\n",
    "            if evaluate:\n",
    "                acc = (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                total_acc += acc\n",
    "\n",
    "                labels = labels.data.cpu().numpy()\n",
    "                predic = outputs.argmax(dim=1).data.cpu().numpy()\n",
    "                labels_all = np.append(labels_all, labels)\n",
    "                predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    if evaluate:\n",
    "        report = metrics.classification_report(labels_all, predict_all, target_names=['benign', 'vulnerable'], digits=4)\n",
    "        confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "        print(f'Test Accuracy: {total_acc / len(input_data): .4f}')\n",
    "        print(report)\n",
    "        print(confusion)\n",
    "\n",
    "remove_file_if_exist(intermediate_ct_train_path)\n",
    "remove_file_if_exist(intermediate_ct_val_path)\n",
    "\n",
    "generate_ct_intermediate_dataset(train_dataset, intermediate_ct_train_path, False)\n",
    "generate_ct_intermediate_dataset(val_dataset, intermediate_ct_val_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MsgTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 148/148 [01:43<00:00,  1.43it/s]\n",
      "100%|██████████| 37/37 [00:26<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.9746    0.9795    0.9770      2389\n",
      "  vulnerable     0.9788    0.9737    0.9763      2322\n",
      "\n",
      "    accuracy                         0.9767      4711\n",
      "   macro avg     0.9767    0.9766    0.9766      4711\n",
      "weighted avg     0.9767    0.9767    0.9766      4711\n",
      "\n",
      "[[2340   49]\n",
      " [  61 2261]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from transformers import RobertaModel, RobertaTokenizerFast\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import os\n",
    "import random\n",
    "\n",
    "# definitions\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "BERT_CONFIG = 'roberta-base'\n",
    "labels = {0:0, 1:1}\n",
    "BATCH_SIZE = 128\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(BERT_CONFIG)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length=512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['commit_message']]\n",
    "        self.ids = [id_ for id_ in df['id']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_ids = self.ids[idx]\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_ids, batch_texts, batch_y\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = RobertaModel.from_pretrained(BERT_CONFIG)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if BERT_CONFIG == 'roberta-large':\n",
    "            self.linear = nn.Linear(1024, len(labels))\n",
    "        else:\n",
    "            self.linear = nn.Linear(768, len(labels))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        # final_layer = self.relu(linear_output) # IMPO CHANGE\n",
    "        return linear_output\n",
    "\n",
    "    def check_parameters(self):\n",
    "        print('The number of Bert parameters:', self.bert.num_parameters())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# generate intermediate data by MsgTransformer and evaluation\n",
    "model = BertClassifier()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(finetuned_mt_model_path))\n",
    "\n",
    "def generate_mt_intermediate_dataset(input_data, intermediate_data_path, evaluate=True):\n",
    "    data_loader = torch.utils.data.DataLoader(Dataset(input_data), batch_size=BATCH_SIZE)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    total_acc = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ids, texts, labels in tqdm(data_loader):\n",
    "            labels = labels.to(device)\n",
    "            masks = texts['attention_mask'].to(device)\n",
    "            input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "            outputs = model(input_ids, masks)\n",
    "\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1).tolist()\n",
    "            assert(len(probs) == len(labels))\n",
    "            pred_list = outputs.argmax(dim=1).data.cpu().numpy().tolist()\n",
    "            assert(len(probs) == len(pred_list))\n",
    "            assert(len(probs) == len(ids))\n",
    "            for i in range(len(probs)):\n",
    "                id_ = ids[i]\n",
    "                prob = probs[i]\n",
    "                label = int(labels[i])\n",
    "                pred_ = int(pred_list[i])\n",
    "                content = '\\t'.join([str(i) for i in [id_] + prob + [pred_] + [label]]) + '\\n'\n",
    "                write_to_file(content, intermediate_data_path)\n",
    "\n",
    "            if evaluate:\n",
    "                acc = (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                total_acc += acc\n",
    "\n",
    "                labels = labels.data.cpu().numpy()\n",
    "                predic = outputs.argmax(dim=1).data.cpu().numpy()\n",
    "                labels_all = np.append(labels_all, labels)\n",
    "                predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    if evaluate:\n",
    "        report = metrics.classification_report(labels_all, predict_all, target_names=['benign', 'vulnerable'], digits=4)\n",
    "        confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "        print(f'Test Accuracy: {total_acc / len(input_data): .4f}')\n",
    "        print(report)\n",
    "        print(confusion)\n",
    "\n",
    "df_train = pd.read_json(init_train_path)\n",
    "df_val = pd.read_json(init_val_path)\n",
    "\n",
    "remove_file_if_exist(intermediate_mt_train_path)\n",
    "remove_file_if_exist(intermediate_mt_val_path)\n",
    "\n",
    "generate_mt_intermediate_dataset(df_train, intermediate_mt_train_path, False)\n",
    "generate_mt_intermediate_dataset(df_val, intermediate_mt_val_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine everything into intermediate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "intermediate_train_path = f'{intermediate_directory}/train.txt'\n",
    "intermediate_val_path = f'{intermediate_directory}/val.txt'\n",
    "intermediate_test_path = f'{intermediate_directory}/test.txt'\n",
    "\n",
    "def generate_intermediate_dataset(intermediate_mt_data_path, intermediate_ct_data_path, intermediate_data_path, init_data_path):\n",
    "    with open(intermediate_mt_data_path) as f:\n",
    "        mt_data_list = f.read().split('\\n')\n",
    "    \n",
    "    with open(intermediate_ct_data_path) as f:\n",
    "        ct_data_list = f.read().split('\\n')\n",
    "    \n",
    "    mt_data_list = mt_data_list[:-1] if not mt_data_list[-1] else mt_data_list\n",
    "    ct_data_list = ct_data_list[:-1] if not ct_data_list[-1] else ct_data_list\n",
    "\n",
    "    assert(len(mt_data_list) == len(ct_data_list))\n",
    "\n",
    "    for i in range(len(mt_data_list)):\n",
    "        mt_data = mt_data_list[i].split('\\t')\n",
    "        ct_data = ct_data_list[i].split('\\t')\n",
    "        assert(mt_data[0] == ct_data[0])\n",
    "        assert(mt_data[-1] == ct_data[-1])\n",
    "        data_id = mt_data[0]\n",
    "        label = mt_data[-1]\n",
    "        mt_pred = mt_data[-2]\n",
    "        ct_pred = ct_data[-2]\n",
    "        content = '\\t'.join([data_id] + mt_data[1:3] + ct_data[1:3] + [str(mt_pred)] + [str(ct_pred)] + [label])\n",
    "        content = content + '\\n' if i < len(mt_data_list) - 1 else content\n",
    "        write_to_file(content, intermediate_data_path)\n",
    "\n",
    "remove_file_if_exist(intermediate_train_path)\n",
    "remove_file_if_exist(intermediate_val_path)\n",
    "\n",
    "generate_intermediate_dataset(intermediate_mt_train_path, intermediate_ct_train_path, intermediate_train_path, init_train_path)\n",
    "generate_intermediate_dataset(intermediate_mt_val_path, intermediate_ct_val_path, intermediate_val_path, init_val_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate_val_path: /root/autodl-tmp/intermediate/combined/val.txt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "EPOCHS = 80\n",
    "LR = 1e-6\n",
    "BATCH_SIZE = 4\n",
    "intermediate_train_path = f'{intermediate_directory}/train.txt'\n",
    "intermediate_val_path = f'{intermediate_directory}/val.txt'\n",
    "MODEL_SAVE_PATH = f'{root_directory}/ensemble_model/{DATASET_MASKING}{DATASET_NAME}'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path) as f:\n",
    "            data_list = f.read().split('\\n')\n",
    "        self.labels = [ int(data.split('\\t')[-1]) for data in data_list ]\n",
    "        self.inputs = []\n",
    "        for data in data_list:\n",
    "            tmp_list = data.split('\\t')[:-1]\n",
    "            for i in range(1, 5):\n",
    "                tmp_list[i] = float(tmp_list[i])\n",
    "            for i in range(5, len(tmp_list)):\n",
    "                tmp_list[i] = int(tmp_list[i])\n",
    "            self.inputs.append(tmp_list)\n",
    "        \n",
    "        assert(len(self.labels) == len(self.inputs))\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x[0], x[1], x[2], x[3], x[4], x[5], x[6], y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(input_dim, 20)\n",
    "        self.out = nn.Linear(20, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def train(model, train_dataset, val_dataset):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        for x0, x1, x2, x3, x4, x5, x6, y in tqdm(train_dataloader):\n",
    "            x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x0, x1, x2, x3, x4, x5, x6, y in val_dataloader:\n",
    "                x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "\n",
    "                loss = criterion(y_pred, y)\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "                acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .4f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_dataset): .4f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_dataset): .4f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_dataset): .4f}')\n",
    "\n",
    "        val_acc = f'{total_acc_val / len(val_dataset):.4f}'\n",
    "        torch.save(model.state_dict(), f'{MODEL_SAVE_PATH}/ensemble2_{val_acc}_epoch{epoch_num + 1}.pt')\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    real_sample_count = 0\n",
    "    total_acc_test = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x0, x1, x2, x3, x4, x5, x6, y in test_dataloader:\n",
    "            data_id = x0[0]\n",
    "            # for only-bigvul testing starts ---- \n",
    "            if not data_id.startswith('bigvul_'): continue\n",
    "            real_sample_count += 1\n",
    "            # for only-bigvul testing ends ---- \n",
    "            \n",
    "            x = torch.transpose(torch.stack([x1, x2, x3, x4]), 0, 1).float().to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            y = y.data.cpu().numpy()\n",
    "            predic = y_pred.argmax(dim=1).data.cpu().numpy()\n",
    "            predic_n = predic[0]\n",
    "            mt_pred = x5\n",
    "            ct_pred = x6\n",
    "                        \n",
    "            if predic_n == 0:\n",
    "                print('predic_n == 0 data_id:', data_id)\n",
    "            \n",
    "            labels_all = np.append(labels_all, y)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "    \n",
    "    # fake neg sample for only-bigvul testing starts ---- \n",
    "    predict_all = np.append(predict_all, 0)\n",
    "    labels_all = np.append(labels_all, 0)\n",
    "    # fake neg sample for only-bigvul testing ends ---- \n",
    "\n",
    "    report = metrics.classification_report(labels_all, predict_all, target_names=['benign', 'vulnerable'], digits=4)\n",
    "    confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_dataset): .4f}')\n",
    "    print(report)\n",
    "    print(confusion)\n",
    "    print('real_sample_count:', real_sample_count)\n",
    "\n",
    "train_dataset = MyDataset(intermediate_train_path)\n",
    "val_dataset = MyDataset(intermediate_val_path)\n",
    "print('intermediate_val_path:', intermediate_val_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path: /root/autodl-tmp/ensemble_model/combined/ensemble2_0.9769_epoch80.pt\n",
      "predic_n == 0 data_id: bigvul_f0d1bec9d58d4c038d0ac958c9af82be6eb18045\n",
      "Test Accuracy:  0.1231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.5000    1.0000    0.6667         1\n",
      "  vulnerable     1.0000    0.9983    0.9991       581\n",
      "\n",
      "    accuracy                         0.9983       582\n",
      "   macro avg     0.7500    0.9991    0.8329       582\n",
      "weighted avg     0.9991    0.9983    0.9986       582\n",
      "\n",
      "[[  1   0]\n",
      " [  1 580]]\n",
      "real_sample_count: 581\n"
     ]
    }
   ],
   "source": [
    "mkdir_if_not_exist(MODEL_SAVE_PATH)\n",
    "model = MLP(4, 2)\n",
    "saved_model_name = 'ensemble2_0.9769_epoch80.pt'\n",
    "model.load_state_dict(torch.load(f'{MODEL_SAVE_PATH}/{saved_model_name}'))\n",
    "print('model path:', f'{MODEL_SAVE_PATH}/{saved_model_name}')\n",
    "\n",
    "evaluate(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
